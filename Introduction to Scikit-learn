# IPython with anaconda

# coding: utf-8

# In[1]:

import numpy as np
import scipy.stats as st
import sklearn.linear_model as lm
import matplotlib.pyplot as plt
%matplotlib inline


# In[2]:

f = lambda x: np.exp(3*x)


# In[3]:

x_tr = np.linspace(0., 2, 200)
y_tr = f(x_tr)


# In[4]:

x = np.array([0, .1, .2, .5, .8, .9, 1])
y = f(x) + np.random.randn(len(x))


# In[5]:

plt.plot(x_tr[:100], y_tr[:100], '--k')
plt.plot(x, y, 'ok', ms=10)


# In[6]:

lr = lm.LinearRegression()
lr.fit(x[:, np.newaxis], y)
y_lr = lr.predict(x_tr[:, np.newaxis])


# In[7]:

plt.plot(x_tr, y_tr, '--k')
plt.plot(x_tr, y_lr, 'g')
plt.plot(x, y, 'ok', ms=10)
plt.xlim(0,1)
plt.ylim(y.min()-1, y.max()+1)
plt.title("Linear regression")


# In[8]:

lrp = lm.LinearRegression()
plt.plot(x_tr, y_tr, '--k')
for deg in [2,5]:
    lrp.fit(np.vander(x, deg+1), y)
    y_lrp = lrp.predict(np.vander(x_tr, deg +1))
    plt.plot(x_tr, y_lrp,
                label='degree ' + str(deg))
    plt.legend(loc=2)
    plt.xlim(0, 1.4)
    plt.ylim(-10, 40)
    print(' '.join(['%.2f' % c for c in
                       lrp.coef_]))
plt.plot(x, y, 'ok', ms=10)
plt.title("Linear regression")


# In[10]:

ridge = lm.RidgeCV()
plt.plot(x_tr, y_tr, '--k')

for deg in [2,5]:
    ridge.fit(np.vander(x, deg+1), y)
    y_ridge = ridge.predict(np.vander(x_tr, deg +1))
    plt.plot(x_tr, y_ridge,
                label='degree ' + str(deg))
    plt.legend(loc=2)
    plt.xlim(0, 1.5)
    plt.ylim(-5, 80)
    print(' '.join(['%.2f' % c for c in
                       ridge.coef_]))
plt.plot(x, y, 'ok', ms=10)
plt.title("Ridge regression")





